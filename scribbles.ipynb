{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "- Rendering loop in cpp/rust - also valuable experience :)\n",
    "- Similarly to how we do binning with alpha, we could do it with bounding boxes to speed up rendering loop (even though we would be looking at some gsns multiple times, it probably pays off)\n",
    "\n",
    "\\#\\#\\#\\#\\#\n",
    "\n",
    "- depth map AND pre-compute alpha? Should be possible -- iterate over x's, y's and depths, check with depth_map (computed by virtue of random sampling) whether to actually perform the computation. Could even make depth vs depth_map part of mask if we're clever about it (e.g. max depth over grids, check if x's and y's of one primitive are contained in those grids)?\n",
    "- pre-compute alpha while sorting\n",
    "- replace sorting by top-K iteratively, make sorting \"part of rendering\" and compute alpha in parallell while sorting... Sorting is becoming a slow part -- check out [Radix Sort](https://www.geeksforgeeks.org/radix-sort/)\n",
    "- Is batched rendering possible? Maybe we have to make major changes to do so, but that's probably the weakest joint. \n",
    "- Further explore: Is it faster to render float16 images? Doing the full calculation in float16 doesn't work, but maybe the rendering is okay? Are other memory improvements possible?\n",
    "- Bug: depending on `skip` parameter, the rendered pictures look different\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scribble notebook\n",
    "The plan is to use this to make first experiments, which will later be turned into a cleaner implementation. \n",
    "For now, it is based on https://github.com/thomasantony/splat/blob/master/notes/00_Gaussian_Projection.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "\n",
    "from utils.Camera import Camera\n",
    "from utils.util_gau import load_ply, GaussianData\n",
    "from pathlib import Path \n",
    "from decouple import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_objects = load_ply(str(Path(config('MODEL_PATH'))/'debug/point_cloud/iteration_30000/point_cloud.ply'), dtype=np.float64, return_type='gm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.rendering import ParRenderer \n",
    "\n",
    "(w, h) = (400, 400)\n",
    "\n",
    "renderer = ParRenderer(gaussian_objects)\n",
    "\n",
    "camera = Camera(h, w, position=(-1.6, 2., 1.4), target=(-.15, 1.5, .7))# target is pos for one of the gaussians\n",
    "bitmap_parts = list(tqdm(renderer.plot_model_par_multiprimitives(camera, n_threads=20, skip=16000, K=None)))\n",
    "# bitmap_parts = list(tqdm(gaussian_objects.get_bm_parts(camera, n_threads=20)))\n",
    "\n",
    "\n",
    "# do alpha blending post-hoc\n",
    "bitmap = np.zeros(bitmap_parts[0][0].shape)\n",
    "alpha = np.zeros(bitmap_parts[0][1].shape)\n",
    "for bm, al in bitmap_parts:\n",
    "    tmp = (1-alpha)*al\n",
    "    bitmap = bitmap + (1-alpha)[..., np.newaxis]*bm\n",
    "    alpha = alpha + tmp\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(bitmap, vmin=0, vmax=1.)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Code\n",
    "Testing out various ideas described in the blog. I might revisit them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_conics_and_bbs(gaussian_objects, camera: Camera, color: str='blue'):\n",
    "#     # credit to https://github.com/thomasantony/splat/blob/master/notes/00_Gaussian_Projection.ipynb \n",
    "#     # Note: there are some things I would still like to change in this function (e.g. I'm pretty sure coordxy does not need four, but rather two, corners)\n",
    "#     ax = plt.gca()\n",
    "\n",
    "#     for g in gaussian_objects: #zip(gaussian_objects, colors):\n",
    "#         assert isinstance(g, Gaussian)\n",
    "#         (conic, bboxsize_cam, bbox_ndc) = g.get_conic_and_bb(\n",
    "#             camera, \n",
    "#             optimal=True\n",
    "#         )\n",
    "#         if conic is None:\n",
    "#             continue\n",
    "\n",
    "#         A, B, C = conic\n",
    "#         # coordxy is the correct scale to be used with gaussian and is already\n",
    "#         # centered on the gaussian\n",
    "#         coordxy = bboxsize_cam\n",
    "#         x_cam = np.linspace(coordxy[0][0], coordxy[1][0], 100)\n",
    "#         y_cam = np.linspace(coordxy[1][1], coordxy[2][1], 100) # how come the first axis has more than 2 dimensions here?\n",
    "#         X, Y = np.meshgrid(x_cam, y_cam)\n",
    "        \n",
    "#         # 1-sigma ellipse # actually, I think this is the sqrt(3)-sigma ellipse. \n",
    "#         # F = A*X**2 + 2*B*X*Y + C*Y**2 - 3.00\n",
    "#         F = np.sqrt(A*X**2 + 2*B*X*Y + C*Y**2) - 3.00 \n",
    "\n",
    "#         bbox_screen = camera.ndc_to_pixel(bbox_ndc)\n",
    "\n",
    "#         # Use bbox offset to position of gaussian in screen coords to position the ellipse\n",
    "#         x_px = np.linspace(bbox_screen[0][0], bbox_screen[1][0], 100)\n",
    "#         y_px = np.linspace(bbox_screen[2][1], bbox_screen[1][1], 100) # again, why this many dimensions?\n",
    "#         X_px, Y_px = np.meshgrid(x_px, y_px)\n",
    "#         F_val = 0.0\n",
    "#         plt.contour(X_px, Y_px, F, [F_val])\n",
    "\n",
    "#         # Plot a rectangle around the gaussian position based on bb\n",
    "#         ul = bbox_screen[0,:2]\n",
    "#         ur = bbox_screen[1,:2]\n",
    "#         lr = bbox_screen[2,:2]\n",
    "#         ll = bbox_screen[3,:2]\n",
    "#         ax.add_patch(plt.Rectangle((ul[0], ul[1]), ur[0] - ul[0], lr[1] - ur[1], fill=False, alpha=1., color=color))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_opacity_v(gaussian: Gaussian, camera: Camera, bitmap: np.ndarray, alphas: np.ndarray, alpha_thresh: float=None):\n",
    "#     \"\"\"Vectorized version of the plot_opacity function of the original repo - we want to loop as little as possible for speed\"\"\"\n",
    "    \n",
    "    \n",
    "#     conic, bboxsize_cam, bbox_ndc = gaussian.get_conic_and_bb(camera, optimal=True) # different bounding boxes (active areas for gaussian)\n",
    "#     # bboxsize_cam, bbox_ndc = gaussian.get_nonopt_bb(camera)\n",
    "#     h, w = bitmap.shape[:2]\n",
    "#     bbox_screen = camera.ndc_to_pixel(bbox_ndc, w, h)\n",
    "    \n",
    "#     if np.any(np.isnan(bbox_screen)):\n",
    "#         return\n",
    "\n",
    "#     ul = bbox_screen[0,:2] # Bounding box vertices \n",
    "#     ur = bbox_screen[1,:2]\n",
    "#     ll = bbox_screen[3,:2]\n",
    "    \n",
    "#     y1 = max([int(np.floor(ul[1])), 0])\n",
    "#     y2 = min([int(np.ceil(ll[1])), bitmap.shape[0]])\n",
    "    \n",
    "#     x1 = max([int(np.floor(ul[0])), 0])\n",
    "#     x2 = min([int(np.ceil(ur[0])), bitmap.shape[1]])\n",
    "#     nx = x2 - x1\n",
    "#     ny = y2 - y1\n",
    "#     if nx <= 0 or ny <= 0: return bitmap, alphas\n",
    "    \n",
    "#     # TODO: this was an attempt at checking whether we have rendered enough so that the alpha value in a pixel\n",
    "#     # is so high that we do not need to keep rendering deeper Gaussians in that pixel. However, the logic below\n",
    "#     # was slow enough that it did not pay off to implement this\n",
    "#     # TODO: possibly we could be cleverer when checking alpha - e.g. by using information from the foreground.\n",
    "#     # I am working on this\n",
    "\n",
    "#     # midy = y1+ny//2\n",
    "#     # midx = x1+nx//2\n",
    "#     # # if alpha_thresh is not None and (alphas[y1:y2,x1:x2] >= alpha_thresh).sum() >= nx*ny/3: \n",
    "#     # #     return bitmap, alphas \n",
    "#     # if alpha_thresh is not None and min([ # check alpha on bb borders (heuristic)\n",
    "#     #     # alphas[y1:y2, x1].max(),\n",
    "#     #     # alphas[y1:y2, x2-1].max(),\n",
    "#     #     # alphas[y1, x1:x2].max(),\n",
    "#     #     # alphas[y2-1, x1:x2].max(),\n",
    "#     #     alphas[midy, x1],\n",
    "#     #     alphas[midy, x2-1],\n",
    "#     #     alphas[y1, midx],\n",
    "#     #     alphas[y2-1, midx],\n",
    "#     #     alphas[midx,midx]\n",
    "#     # ]) >= alpha_thresh: \n",
    "#     #     return bitmap, alphas\n",
    "#     # conic = gaussian.get_conic(camera)\n",
    "    \n",
    "#     A, B, C = conic # precision matrix is (A, B; B, C)\n",
    "\n",
    "#     # Extract out inputs for the gaussian\n",
    "#     coordxy = bboxsize_cam\n",
    "#     x_cam_1 = coordxy[0][0]   # ul\n",
    "#     x_cam_2 = coordxy[1][0]   # ur\n",
    "#     y_cam_1 = coordxy[1][1]   # ur (y)\n",
    "#     y_cam_2 = coordxy[2][1]   # lr\n",
    "\n",
    "#     opacity = gaussian.opacity \n",
    "\n",
    "#     camera_dir = gaussian.pos - camera.position\n",
    "#     camera_dir = camera_dir / np.linalg.norm(camera_dir) # normalized camera viewing direction\n",
    "#     color = gaussian.get_color(camera_dir)\n",
    "#     y_cam, x_cam = np.meshgrid(np.linspace(y_cam_1, y_cam_2, ny), np.linspace(x_cam_1, x_cam_2, nx), indexing='ij')\n",
    "#     power = -(A*x_cam**2 + C*y_cam**2)/2.0 - B * x_cam * y_cam\n",
    "#     # power = np.clip(power, -np.inf, 0.)\n",
    "#     alpha_ = opacity * np.exp(power)\n",
    "#     bitmap[y1:y2, x1:x2] = bitmap[y1:y2, x1:x2] + ((1-alphas[y1:y2, x1:x2])*alpha_).reshape(ny, nx, 1) * color[0:3].reshape(1, 1, -1)\n",
    "#     alphas[y1:y2, x1:x2] = alphas[y1:y2, x1:x2] + (1-alphas[y1:y2, x1:x2]) * alpha_ \n",
    "#     return bitmap, alphas \n",
    "\n",
    "# def plot_opacity_multi(gaussians: MultiGaussian, camera: Camera, bitmap: np.ndarray, alphas: np.ndarray, alpha_thresh: float=None):\n",
    "#     \"\"\"Vectorized version of the plot_opacity function of the original repo - we want to loop as little as possible for speed\"\"\"\n",
    "#     def scale_wh(tnsr: np.ndarray, h: int, w: int):\n",
    "#         # scale values of tnsr's -1st axis, which has length 2, from -1, 1 to resp. 0, h and 0, w\n",
    "#         # replace this: np.array([(points_ndc[0] + 1) * width_half, (1.0 - points_ndc[1]) * height_half])\n",
    "#         tnsr = np.stack([tnsr[:, :, 0]+1, 1-tnsr[:, :, 1]], axis=-1)\n",
    "#         tnsr = tnsr * np.stack([np.ones(tnsr.shape[:-1])*h, np.ones(tnsr.shape[:-1])*w], axis=-1)\n",
    "#         return tnsr / 2\n",
    "\n",
    "#     conic_, bboxsize_cam, bbox_ndc = gaussians.get_conic_and_bb(camera, optimal=True) # different bounding boxes (active areas for gaussian)\n",
    "#     h, w = bitmap.shape[:2]\n",
    "#     # bbox_screen = camera.ndc_to_pixel(bbox_ndc, w, h)\n",
    "#     bbox_screen = scale_wh(bbox_ndc, h, w)\n",
    "    \n",
    "#     if np.any(np.isnan(bbox_screen)):\n",
    "#         return\n",
    "\n",
    "#     ul = bbox_screen[:, 0,:2] # Bounding box vertices \n",
    "#     ur = bbox_screen[:, 1,:2]\n",
    "#     ll = bbox_screen[:, 3,:2]\n",
    "    \n",
    "#     y1_ = np.maximum(np.floor(ul[:, 1]), np.zeros(len(gaussians))).astype(int)\n",
    "#     x1_ = np.maximum(np.floor(ul[:, 0]), np.zeros(len(gaussians))).astype(int)\n",
    "\n",
    "#     y2_ = np.minimum(np.ceil(ll[:, 1]), bitmap.shape[0]*np.ones(len(gaussians))).astype(int)\n",
    "#     x2_ = np.minimum(np.ceil(ur[:, 0]), bitmap.shape[1]*np.ones(len(gaussians))).astype(int)\n",
    "\n",
    "#     mask = np.logical_and(x2_ > x1_, y2_ > y1_)\n",
    "#     x1_ = x1_[mask]\n",
    "#     x2_ = x2_[mask]\n",
    "#     y1_ = y1_[mask]\n",
    "#     y2_ = y2_[mask]\n",
    "#     conic_ = conic_[mask]\n",
    "\n",
    "#     nx_ = x2_ - x1_\n",
    "#     ny_ = y2_ - y1_\n",
    "#     # if nx <= 0 or ny <= 0: return bitmap, alphas\n",
    "\n",
    "#     # Extract out inputs for the gaussian\n",
    "#     coordxy = bboxsize_cam[mask]\n",
    "#     x_cam_1_ = coordxy[:, 0, 0]   # ul\n",
    "#     x_cam_2_ = coordxy[:, 1, 0]   # ur\n",
    "#     y_cam_1_ = coordxy[:, 1, 1]   # ur (y)\n",
    "#     y_cam_2_ = coordxy[:, 2, 1]   # lr\n",
    "\n",
    "#     opacity_ = gaussians.opacity[mask]\n",
    "\n",
    "#     # camera_dir = gaussians.pos - camera.position.reshape((1, *camera.position.shape))\n",
    "#     # camera_dir = camera_dir / np.linalg.norm(camera_dir, axis=-1) # normalized camera viewing direction\n",
    "#     # color = gaussians.get_color(camera_dir)\n",
    "#     color_ = gaussians.get_color(None)[mask] # TODO: would be nice if in MultiGaussian we could index with a mask prior to computations like these, rather than doing the computation and then selecting afterwards\n",
    "    \n",
    "    \n",
    "#     for x_cam_1, x_cam_2, y_cam_1, y_cam_2, x1, x2, y1, y2, nx, ny, opacity, color, conic in zip(\n",
    "#         x_cam_1_, \n",
    "#         x_cam_2_, \n",
    "#         y_cam_1_, \n",
    "#         y_cam_2_, \n",
    "#         x1_, \n",
    "#         x2_, \n",
    "#         y1_, \n",
    "#         y2_, \n",
    "#         nx_, \n",
    "#         ny_, \n",
    "#         opacity_, \n",
    "#         color_, \n",
    "#         conic_\n",
    "#     ):\n",
    "#         # if nx <= 0 or ny <= 0: continue\n",
    "#         A, B, C = conic \n",
    "#         y_cam, x_cam = np.meshgrid(np.linspace(y_cam_1, y_cam_2, ny), np.linspace(x_cam_1, x_cam_2, nx), indexing='ij')\n",
    "#         power = -(A*x_cam**2 + C*y_cam**2)/2.0 - B * x_cam * y_cam\n",
    "#         # power = np.clip(power, -np.inf, 0.)\n",
    "#         alpha_ = opacity * np.exp(power)\n",
    "#         bitmap[y1:y2, x1:x2] = bitmap[y1:y2, x1:x2] + ((1-alphas[y1:y2, x1:x2])*alpha_).reshape(ny, nx, 1) * color[0:3].reshape(1, 1, -1)\n",
    "#         alphas[y1:y2, x1:x2] = alphas[y1:y2, x1:x2] + (1-alphas[y1:y2, x1:x2]) * alpha_ \n",
    "#     return bitmap, alphas \n",
    "    \n",
    "#     # below is WIP code\n",
    "#     # np.linspace(np.zeros((2,)), np.array([1., 2.]), np.array([10, 20])) is not valid python, but\n",
    "#     # np.linspace(np.zeros((2,)), np.array([1., 2.]), 10) is\n",
    "#     n_gaussians = mask.sum()\n",
    "\n",
    "#     ymin, ymax = np.min(y1_), np.max(y2_)\n",
    "#     xmin, xmax = np.min(x1_), np.max(x2_)\n",
    "#     alpha_computations = np.zeros((n_gaussians, ymax - ymin, xmax - xmin))\n",
    "#     coefs = np.zeros(alpha_computations.shape)\n",
    "#     side_coefs = np.zeros(alpha_computations.shape)\n",
    "\n",
    "#     def fill_array(i: int):\n",
    "#         \"\"\"Take an index argument to fill the above tensor with values in a vectorized fashion\"\"\"\n",
    "#         A, B, C = conic_[i][0], conic_[i][1], conic_[i][2]\n",
    "#         y_cam, x_cam = np.meshgrid(np.linspace(y_cam_1_[i], y_cam_2_[i], ny_[i]), np.linspace(x_cam_1_[i], x_cam_2_[i], nx_[i]), indexing='ij')\n",
    "#         power = -(A*x_cam**2 + C*y_cam**2)/2.0 - B * x_cam * y_cam\n",
    "#         alpha_computations[i, y1_[i]-ymin:y2_[i]-ymin, x1_[i]-xmin:x2_[i]-xmin] = opacity_[i] * np.exp(power)\n",
    "#         # return opacity_[i] * np.exp(power)\n",
    "#     def prod_arr(i: int):\n",
    "#         # return np.prod(1-alpha_computations[:i+1], axis=0)\n",
    "#         coefs[i] = np.prod(1-alpha_computations[:i+1], axis=0)\n",
    "#         # return np.prod(1-alpha_computations[:i+1], axis=0)\n",
    "#     def other_coefs(i: int):\n",
    "#         # let a:=alpha_computations\n",
    "#         # return a[i] + (1-a[i]) * a[i-1] + (1-a[i])(1-a[i-1])*a[i-2] + ...\n",
    "#         # Letting p[j] := (1-a[j]) * ... * (1-a[0]), then p is coefs, and we therefore return\n",
    "#         # a[i] * p[i] / p[i] + a[i-1] * p[i] / p[i-1] + ...\n",
    "#         side_coefs[i] = (coefs[i].reshape(1, *coefs[i].shape) * alpha_computations[:i+1] / coefs[:i+1]).sum(axis=0)\n",
    "#         # side_coefs[i] = np.stack([coefs[i] / np.maximum(coefs[j], 1e-12) * alpha_computations[j] for j in range(i+1)], axis=0).sum(axis=0)\n",
    "#         # return np.stack([coefs[i] / np.maximum(coefs[j], 1e-12) * alpha_computations[j] for j in range(i+1)], axis=0).sum(axis=0)\n",
    "#     np.vectorize(fill_array)(range(n_gaussians))\n",
    "#     np.vectorize(prod_arr)(range(n_gaussians)) # coefs[i] = (1-a[0]) * ... * (1-a[i])\n",
    "#     np.vectorize(other_coefs)(range(n_gaussians)) \n",
    "#     # for func in [fill_array, prod_arr, other_coefs]:\n",
    "#     #     for i in range(n_gaussians): func(i)\n",
    "#     # np.apply_along_axis(fill_array, axis=0, arr=np.arange(n_gaussians, dtype=int).reshape(-1, 1))# (range(n_gaussians))\n",
    "#     # np.apply_along_axis(prod_arr, axis=0, arr=np.arange(n_gaussians, dtype=int).reshape(-1, 1))# (range(n_gaussians)) # coefs[i] = (1-a[0]) * ... * (1-a[i])\n",
    "#     # np.apply_along_axis(other_coefs, axis=0, arr=np.arange(n_gaussians, dtype=int).reshape(-1, 1))# (range(n_gaussians)) \n",
    "\n",
    "#     new_alphas = side_coefs + coefs * alphas[ymin:ymax, xmin:xmax].reshape(1, *alpha_computations.shape[1:]) \n",
    "#     # TODO: below, do I have to multiply by something more too?\n",
    "#     new_colors = bitmap[ymin:ymax, xmin:xmax].reshape(1, *alpha_computations.shape[1:], 3) + new_alphas.reshape(*new_alphas.shape, 1) * color_[:, :3].reshape(-1, 1, 1, 3)\n",
    "#     bitmap[ymin:ymax, xmin:xmax] = new_colors.sum(axis=0)\n",
    "#     alphas[ymin:ymax, xmin:xmax] = new_alphas[-1]\n",
    "#     return bitmap, alphas \n",
    "\n",
    "# # # Plot some Gaussians\n",
    "# # loc_scaler = 1\n",
    "# # scale_scaler = .05\n",
    "# # rot_scaler = 10\n",
    "# # n_gaussians = 50\n",
    "# # loc_bias = 0. # np.ones(3,) * -.1\n",
    "\n",
    "# # gaussians_debug = [\n",
    "# #     Gaussian((np.random.rand(3, )-.5 + loc_bias)*2*loc_scaler, np.random.rand(3)*scale_scaler, np.random.rand(4)*rot_scaler, np.array([1.]), np.array([ 1.772484, -1.772484,  1.772484])) for _ in range(n_gaussians)\n",
    "# # ]\n",
    "# # gaussian_objects = gaussians_debug\n",
    "\n",
    "# # (h, w) = (300, 400)\n",
    "# # camera = Camera(h, w)\n",
    "# # # Get gaussian indices sorted by depth\n",
    "# # indices = np.argsort([g.get_depth(camera) for g in gaussian_objects]) # TODO: vectorize get_depth\n",
    "\n",
    "# # # Initialize a bitmap with alpha channel of size w x h\n",
    "\n",
    "# # bitmap = np.zeros((h, w, 3), np.float32)\n",
    "# # alphas = np.zeros((h, w), np.float32)\n",
    "\n",
    "# # plt.figure(figsize=(6,6))\n",
    "# # for idx in indices:\n",
    "# #     # bitmap, alphas = plot_opacity(gaussian_objects[idx], camera, bitmap, alphas)\n",
    "# #     bitmap, alphas = plot_opacity_v(gaussian_objects[idx], camera, bitmap, alphas)\n",
    "# # print(f'after execution, {bitmap.max()=}')\n",
    "# # # Plot the bitmap\n",
    "# # plt.imshow(bitmap, vmin=0, vmax=1.0)\n",
    "\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old classes for plotting which don't use MultiGaussian\n",
    "\n",
    "# def helper_primitives(indices: List[int], camera, bitmap, alphas, alpha_thresh):\n",
    "#     for idx in indices:\n",
    "#         bitmap, alphas = plot_opacity_v(gaussian_objects[idx], camera, bitmap, alphas, alpha_thresh)\n",
    "#     return bitmap, alphas \n",
    "\n",
    "# def plot_model_par_primitives(camera, gaussian_objects: List[Gaussian], alpha_thresh: float=None, n_threads:int=1):\n",
    "#     \"\"\"Parallellize image rendering by splitting the sorted list of Gaussians and rendering them individually.\n",
    "#     Requires blending the segments later (for now).\n",
    "#     \"\"\"\n",
    "#     print('Sorting the gaussians by depth')\n",
    "#     indices = np.argsort([gau.get_depth(camera) for gau in gaussian_objects])# [::-1] # fast-ish. probably get_depth is slowing it down (vectorization/parallellization TODO)\n",
    "#     w, h = camera.w, camera.h\n",
    "    \n",
    "#     print('Plotting with', len(gaussian_objects), 'gaussians')\n",
    "#     bitmap = np.zeros((h, w, 3), np.float32)\n",
    "#     alphas = np.zeros((h, w), np.float32)\n",
    "#     skip = len(indices) // (3*n_threads) # arbitrary choice TODO\n",
    "#     gsns = [indices[i*skip:(i+1)*skip] for i in range(len(indices)//skip + int(len(indices)%skip != 0))]\n",
    "#     with mp.Pool(n_threads) as pool:\n",
    "#         for r in pool.imap(\n",
    "#             functools.partial(\n",
    "#                 helper_primitives,\n",
    "#                 alpha_thresh=alpha_thresh, \n",
    "#                 camera=camera,# None,\n",
    "#                 bitmap=bitmap,\n",
    "#                 alphas=alphas\n",
    "#             ), \n",
    "#             gsns\n",
    "#         ): \n",
    "#             yield r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test IterativeImageSegmenter\n",
    "# # The idea is to segment an image such that each segment has roughly the same number of Gaussians.\n",
    "# # It's still not perfect (see blog)\n",
    "# # TODO: There seems to be a bug that causes some of the splits to be sub-optimal. Have to investigate\n",
    "# loc_scaler = 1\n",
    "# scale_scaler = .03\n",
    "# rot_scaler = 10\n",
    "# n_gaussians = 30\n",
    "# loc_bias = 0. \n",
    "\n",
    "# gaussians_debug = [\n",
    "#     Gaussian((np.random.rand(3, )-.5 + loc_bias)*2*loc_scaler, np.random.rand(3)*scale_scaler, np.random.rand(4)*rot_scaler, np.array([1.]), np.array([ 1.772484, -1.772484,  1.772484])) for _ in range(n_gaussians)\n",
    "# ]\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "# camera = Camera(100, 100)\n",
    "# plot_conics_and_bbs(gaussians_debug, camera)\n",
    "# image = SubImage(np.zeros((100, 100)), (0, 0), (100, 100), camera)\n",
    "# pset = PrimitiveSet(gaussians_debug)\n",
    "# sset = PrimitiveSubset(pset, list(range(len(gaussians_debug))))\n",
    "# segmenter = IterativeImageSegmenter(sset, image, camera, thresh=3)\n",
    "\n",
    "# for i in range(7):\n",
    "#     bx, by = segmenter.cut(i)\n",
    "#     ul, lr = segmenter.cuts[-1]['corners']\n",
    "#     ymin, xmin = ul\n",
    "#     ymax, xmax = lr \n",
    "#     if bx is None:\n",
    "#         # plot y splitting line\n",
    "#         plt.plot([xmin, xmax], [by]*2)\n",
    "#         plt.text((xmax+xmin)/3*2, by, str(i))\n",
    "#     else:\n",
    "#         plt.plot([bx]*2, [ymin, ymax])\n",
    "#         plt.text(bx, (ymin+ymax)/3*2, str(i))\n",
    "    \n",
    "# plt.xlim([0, camera.w])\n",
    "# plt.ylim([0, camera.h])\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
